{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOVG9m4WzjmtOe7DyYONPV4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Level 1 Lab- Binary Classification & Regression for Classification\n","Level 1 is designed for people with little or no previous experience.\n","\n","## What is classification?\n","**_Classification_** is the process of predicting a _categorical label_ for a sample based on some characteristics about that sample.  Categorical labels just mean you are labling the sample with a name or identifying number, not trying to calculate some mathematical value related to the sample.  This is what separates _classification_ from _regression_.\n","\n","As the title of the lab implies, we will be learning about how to do classification tasks in Python.  We will be using simple machine learning models to help us in this task.  We can do this easily by making use of the fantastic [Scikit-Learn](https://scikit-learn.org/) library, which contains a treasure-trove of machine learning models and helper code to automate common tasks in model training and evaluation.  Scikit-Learn stops short of \"deep learning\" models (although it does contain one -- the Multi-Layer Perceptron), but the statistical, mathematical, and data mining models it contains will solve a multitude of problems quickly and easily.\n","\n","\n","This lab was initially developed at Arkansas State University by Dr. Jason Causey and expanded by Jennifer Fowler (https://github.com/jennifer-fowler).\n","\n","*Note:* If you are not familiar with Colab or Jupyter Notebooks, we recommended that you participate in a Colab or Jupyter Notebook tutorial to understand how to use the environment. This notebook does not have guidance on the basic operation of the environment.\n","\n","* Video overview of Google Colab: https://youtu.be/NUJMprxho5o\n","\n","* Colab tutorial: https://colab.research.google.com/notebooks/basic_features_overview.ipynb \n","\n","* Jupyter Notebook Beginner's Guide: https://www.dataquest.io/blog/jupyter-notebook-tutorial/ \n","\n","\n","Legend:\n","\n","üìå This symbol is used to describe the Exercises you'll be completing.\n","\n","‚è∏ This symbol is for Detours, supplemental info in case you want it.\n","\n","üèÄ This symbol means it's your turn to play ball and type some code.\n","\n","ü¶û This symbol is used to explain the mathematical concepts related to the exercise."],"metadata":{"id":"wnCsom_YdzGo"}},{"cell_type":"markdown","source":["## üìå Exercise- Regression for Classification --------------------------------------\n","\n","1. Import the Banknote Authentication dataset, and split it into a training dataset and a testing dataset. \n","2. Using sklearn, fit a logistic regression model on the training data.\n","3. Using sklearn, make predictions using the logistic regression model on the testing data.\n","4. Check the accuracy of your model using a confusion matrix, examining the precision and recall.\n","5. Plot a receiver operating characteristic (roc) curve for your model.\n","\n","\n"],"metadata":{"id":"I-3LywvFeMUg"}},{"cell_type":"code","source":["# now let's load the libraries needed for this lab\n","import pandas as pd             # NOTE: our code will refer to Pandas as `pd`\n","import numpy as np              # NOTE: our code will refer to Numpy as `np`\n","import sklearn.linear_model\n","import sklearn.neighbors\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay"],"metadata":{"id":"SE0-3zYReAzE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The \"Banknote Authentication\" dataset\n","The \"Banknote Authentication\" dataset is available from the [UCI Machine Learning repository](https://archive.ics.uci.edu) at <https://archive.ics.uci.edu/ml/datasets/banknote+authentication>.\n","\n","![Banknotes](https://drive.google.com/uc?export=view&id=15WUC3ZhyEEFP2bvJWoNOh9h-iuP0L7pm)\n","\n","### Data Set Information:\n","\n","Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. Wavelet Transform tool were used to extract features from images.\n","\n","### Attribute Information:\n","\n","1. _variance_ of Wavelet Transformed image (continuous)\n","2. _skewness_ of Wavelet Transformed image (continuous)\n","3. _curtosis_ of Wavelet Transformed image (continuous)\n","4. _entropy_ of image (continuous)\n","5. _class_ (integer) \n","\n","\n","### ‚è∏ Detour: CSV or TXT?\n","\n","If you download the file \"`data_banknote_authentication.txt`\" from the UCI repository, you will see the first five lines look like the following:\n","\n","    3.6216,8.6661,-2.8073,-0.44699,0\n","    4.5459,8.1674,-2.4586,-1.4621,0\n","    3.866,-2.6383,1.9242,0.10645,0\n","    3.4566,9.5228,-4.0112,-3.5944,0\n","    0.32924,-4.4552,4.5718,-0.9888,0\n","\n","We can see that this is comma-separated values format (CSV) even though the filename ends in \"`.txt`\".  We can also see there is no header row with column names, so we have to use the \"Attribute Information\" provided (above) to make sense of the columns.\n"],"metadata":{"id":"cqUzaSogeRec"}},{"cell_type":"markdown","source":["## Load the Banknote Dataset\n","Let's load the Banknote dataset directly from UCI's repository.  The [Pandas](https://pandas.pydata.org/) library can do this in a single step.\n","\n","To make things nicer, we will also make a list of the column names (they aren't in the data file), and we will note the ones that are independent variables versus the one (_class_) that is the response or target variable."],"metadata":{"id":"fSJ4qWVMeg2V"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iGiaz7X_da07"},"outputs":[],"source":["# We will use a short version of the names of each attribute, \n","# in the order they appear in the data file (see above):\n","features = [\n","    'variance',\n","    'skewness',\n","    'kurtosis',  # We use the common spelling here (UCI has \"curtosis\")\n","    'entropy',\n","    'class'\n","]\n"]},{"cell_type":"code","source":["# now we will assign the independent features to a variable for the predictors\n","predictors = features[:-1] # all except the last item (all except 'class')\n","\n","# and assign the dependent feature to the target variable\n","target = features[-1]  # only the last item, 'class'"],"metadata":{"id":"69mf2ySknmDE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we will load the data directly from UCI.  The data file does not have a header row with column names, so we will use the ones we defined above.\n","The Pandas `pd.read_csv()` function can do the work for us.  "],"metadata":{"id":"S5Tj0gSEekyr"}},{"cell_type":"code","source":["# Now, we will load the data directly from UCI.  The data file does not have\n","# a header row with column names, so we will use the ones we defined above.\n","bn_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt\", \n","                      header=None, \n","                      names = features)"],"metadata":{"id":"Y2fWSTXAem6Q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's take a look at the dataframe we just created.  In particular, let's see what the labels (_class_) column contains, and how many examples we have for each class.\n","The `class` column labels the **authentic** notes with the class label 0, and the **inauthentic** (counterfeit) notes with the label 1.  We will consider the inauthentic notes as the \"positive\" class for this _binary classification_ problem.\n","\n","Let's define a new list, class_names, to better distinguish the numeric class labels."],"metadata":{"id":"qgpR3CY4tGuN"}},{"cell_type":"code","source":["classes = list(bn_data['class'].unique())\n","# Make a dictionary to map the numeric class to a more descriptive label:\n","map_banknote_class_to_label = {\n","    0: 'authentic',\n","    1: 'inauthentic'\n","}\n","for cls in bn_data['class'].unique():\n","    print(f\"Count for class {cls} ({map_banknote_class_to_label[cls]}): {(bn_data['class'] == cls).sum()}\")\n","\n","class_names = ['authentic', 'inauthentic']"],"metadata":{"id":"wQ4YP9XytFxl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Let's store our data in a simpler way...**\n","\n","It will be much easier to read our code while fitting models if we choose simple names for the variables and response.  We will call the variables `X` and the response `y`, as is common convention in mathematical modeling. \n","The `.values` attribute makes the result a Numpy array instead of a Pandas dataframe.  That won't matter much, but it does mean we can use standard array notation with `X` and `y`."],"metadata":{"id":"tJbdgLUAep8L"}},{"cell_type":"code","source":["X = bn_data[predictors].values\n","y = bn_data[target].values\n"],"metadata":{"id":"DX8AwK2WeqB7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ü¶û  Baseline Model\n","\n","\n","We can see that 762 of the samples are authentic, so if we had a baseline model that always guesses \"authentic\", our accuracy would be $\\frac{762}{1372} \\approx 55\\%$.\n","\n","55% accuracy is only slightly better than guessing, so let's try some models to reach higher accuracy."],"metadata":{"id":"-xY8v1zGe5lX"}},{"cell_type":"markdown","source":["## ‚è∏  DETOUR: Scikit-Learn classifiers\n","The Scikit_Learn library provides several options for classifiers.  Some common choices for simple classification tasks are shown below:\n","\n","* `LogisticRegression` - A linear classifer using logistic regression.\n","* `KNeighborsClassifier` - K-Nearest Neighbors classification.\n","* `SVC` - Support Vector Classifier (uses a Support Vector Machine model).\n","* `DecisionTreeClassifier` - A decision tree classifier.\n","* `RandomForestClassifier` - A random forest classifier.\n","* `AdaBoostClassifier` - Adaptive Boosting (AdaBoost) ensemble classifier.\n","* `GaussianNB` - Naive Bayes' classifer assuming Gaussian distributions.\n","* `GaussianProcessClassifier` - Gaussian process classification (GPC) based on Laplace approximation.\n","* `LinearDiscriminantAnalysis` - Linear discriminant analysis (LDA) classifier.\n","* `QuadraticDiscriminantAnalysis` - Quadratic discriminant analysis (QDA) classifier.\n","* `MLPClassifier` - Multi-Layer Perceptron (neural network) classifier.\n","\n","Check the References for a link to the comparison of these tools.\n","\n","Note that the list above is not comprehensive, as Scikit-Learn provides many more variations and more advanced models.  A more comprehensive list can be seen in this StackOverflow answer: <https://stackoverflow.com/a/54988354>."],"metadata":{"id":"NAqZsDrMuUCc"}},{"cell_type":"markdown","source":["## Choosing a Classification Model\n","\n","With so many options available, how do we choose a model?\n","\n","* \"_Principle of Parsimony_\" - Given more than one model with similar performance, the simpler model is likely the best choice.\n","* _Know your model._ Choose a model that fits the dataset.\n","  * Some models work better with _catgorical_ data (values that are not continuous numbers); some make assumptions about the distributions of the underlying data, etc.\n","  * Before applying a new model, be sure to read about any assumptions it makes, and what the expectations are for data format.\n","\n","**What do we know about our Banknote dataset?**\n","\n","* There are only two classes.  (It is a binary classification problem.)\n","* All variables (except the class label) are continuous numeric values.\n","\n","\n","**What models might be good to try?**\n"],"metadata":{"id":"XmTr8Ejge6OU"}},{"cell_type":"markdown","source":["## Train / Test Split\n","\n","Before we get ahead of ourselves, let's make sure we have a way of **_evaluating_** our model's performance once we have trained it.  To do that fairly, we have to set aside some of the data to serve as a _test set_.  Our model will never get to see those values until we are ready to evaluate its performance.\n","\n","There are many ways to do this, but let's keep it simple for now:  We will select 20% of the total dataset, but we will do it so that the positive/negative balance (or imbalance) from the full dataset is retained.  To help do this with no guesswork, let's use the `StratifiedSplit` tool from Scikit-Learn."],"metadata":{"id":"yqK_5TcTe9LT"}},{"cell_type":"markdown","source":["The `splitter.split()` function is designed to be used in a loop.  We don't actually want that (we just want one split), so we are using the `next()` function to ask for just the first set of splits."],"metadata":{"id":"tBHvUM3Ye_kj"}},{"cell_type":"code","source":["splitter = sklearn.model_selection.StratifiedShuffleSplit(test_size=0.2, random_state=2023)  # test_size sets the ratio of testing examples (20%)\n","train_set, test_set = next(splitter.split(X, y))"],"metadata":{"id":"vUruZtOGeqS8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## A simple linear model\n","\n","Now that we have created a train/test split, let's train a model. \n","\n","For this example, let's pick the simplest classification model:  _logistic regression_.  Logistic regression models are really just simple linear regression models but applied in a classification context.  The model \"learns\" (by fitting the training data) a linear function that produces a hyperplane that best splits the data into the two classes (positive on one side, negative on the other).\n","\n","The logistic regression model is available in Scikit-Learn by using the `sklearn.linear_model.LogisticRegression` class. Check the references for the link to the documentation for this function."],"metadata":{"id":"kUeOGwVrfCr8"}},{"cell_type":"markdown","source":["The first line declares an initialized the model (using all default parameters), and the second line fits the model to our observed training data.\n","\n","Notice the use of the indices we created with the train/test splitter above.  This selects only those rows associated with the _train_ partition from the full datasest.\n","\n","üèÄ       NOW IT'S YOUR TURN:"],"metadata":{"id":"X6yOGpdSfC2M"}},{"cell_type":"code","source":["# now define the model using sklearn.linear_model.LogisticRegression()\n","model = \n","\n","# and fit it to our training data\n","model.fit(X[train_set], y[train_set])"],"metadata":{"id":"o_iz1JcXfCxV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predicting Classes- Two Options\n","Now that we have declared and fit the model, let's use it to make predictions.  The `LogisticRegression` object has two possible ways to do this:\n","\n","* `.predict()` method - predicts the class the example most likely belongs to. This is a method for binary classification. The function will assign a predicted class to each observation.\n","* `.predict_proba()` method - predicts the probability that the example belongs to each possible class. This is one of the ways we can use regression for classification. The function will assign a numerical probability, between 0 and 1, that each observation belongs to the given classes. So if a probability is above 0.5, it most likely belongs in that class. If it's below 0.5, it most likey does not belong in that class.\n","\n","Let's see the first five predictions to make it clear how they are represented.\n","\n","üèÄ       NOW IT'S YOUR TURN:\n"],"metadata":{"id":"xUxjGTIYfQ7X"}},{"cell_type":"code","source":["# use predict_proba() to make predictions on the test data\n","predictions = model.predict_proba(X[test_set])\n","\n","# type the command to print the first few predictions\n","\n"],"metadata":{"id":"Ben7sFyMfC6s"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note that the predictions are shown in scientific notation where the \"`e-N`\" represents the $\\times 10^{N}$ part you would see in a textbook.\n","\n","You can see that the probability of one of the labels for each example is close to 1.0, and the other tends to be very close to 0.0.  The fact that they aren't exactly 1 and 0 shows that there is a bit of uncertainty in the predictions.\n","\n","If we just want to know the probability that a test sample belongs to the positive class ('inauthentic'), we can just look at the value in the second column and ignore the first column (as in `bn_predictions[:,1]`). We will use this trick later.\n","\n","It would also be convenient to create a version of the predictions that contains the _categorical_ label of the most likely class for each test sample.  We can do this in a clever way by using Numpy's `np.argmax()` function to find the _column index_ of the column containing the largest value for each sample.  To do this, we will set `axis=1` to tell Numpy to look at the columns.  Note that this corresponds to a classification threshold of 0.5, which is common.  If you wanted to use a different threshold, you would need to write a bit different code to apply the class labels."],"metadata":{"id":"feMDUkzGfYA-"}},{"cell_type":"code","source":["# establish a variable for the categorical predictions using np.argmax()\n","predictions_categorical = np.argmax(predictions, axis=1)"],"metadata":{"id":"QUJSdzn9fYQv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üèÄ       NOW IT'S YOUR TURN:"],"metadata":{"id":"qbuv3S7vkeJ5"}},{"cell_type":"code","source":["# write a print statement to see the first few predictions\n"],"metadata":{"id":"ZA0TugsCkgFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Measure the performance of the predictions\n","\n","Now we want to see how we did...  Let's look at the information in a few different ways.  The first is to create something called a \"confusion matrix\".  Although the name is a bit odd, the idea is simple:  For each possible class, we want to know how often the model predicted test samples with that class _correctly_ or _incorrectly_.  Note that the prediction can be incorrect in two ways:  We could predict \"positive\" when the truth was that the sample was \"negative\" (we call this a _false positive_), or we could predict the sample is \"negative\" when it was actually conterfeit (we call this a _false negative_).\n","\n","The confusion matrix will create a row for each of the true labels, and a column for each of the predicted lables, with counts for every possible combination of labelings (correct labelings are along the main diagonal).\n","\n","We can quickly examine counts by using the `sklearn.metrics.confusion_matrix()` function. Check the References cell for the link to the documentation about this package.\n","\n","üèÄ       NOW IT'S YOUR TURN:"],"metadata":{"id":"HQUdlX14fYJu"}},{"cell_type":"code","source":["# let's visualize the model accuracy \n","# first in a simple array, using sklearn.metrics.confusion_matrix()\n","# the function will need the parameters: y[test_set], predictions_categorical\n","cm = \n","cm"],"metadata":{"id":"wVIAAUmOfkdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Although we can see the counts here, the output isn't very pretty.  If we want something that is a bit nicer for presentation, we can use ConfusionMatrixDisplay() from Scikit-Learn."],"metadata":{"id":"dMw5nrb1fYMO"}},{"cell_type":"code","source":["# use ConfusionMatrixDisplay() to plot and show the matrix\n","ConfusionMatrixDisplay(cm).plot()"],"metadata":{"id":"GPKCXDwrfnP8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**ü¶û Wow!**\n","\n","The `LogisticRegression` classifier did a fantastic job!  It is only mis-classifying one of the total 275 test examples.  That is $\\frac{275-1}{275} = \\frac{274}{275} \\approx 0.99 = 99\\%$ accuracy!\n","\n","Let's look at some other ways of generating metrics about the classification performance.  First, we can ask Scikit-Learn to calculate the accuracy for us with `sklearn.metrics.accuracy_score()`.\n","\n","üèÄ       NOW IT'S YOUR TURN:"],"metadata":{"id":"Ht6jtbllfnWM"}},{"cell_type":"code","source":["# examine the accuracy of the model\n","# using sklearn.metrics.accuracy_score()\n","# the function will need the parameters: y[test_set], predictions_categorical\n","score = \n","score\n"],"metadata":{"id":"78QVgkAlfnat"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can also use the `sklearn.metrics.classification_report()` function to print a summary of the performance (this will work with binary or multi-class classifiers).\n","\n","### ‚è∏ Detour: Precision & Recall\n","\n","**_Precision_** is $\\frac{TP}{TP + FP}$ where $TP$ means \"_true positive_\" (a sample that was predicted positive and the prediction was correct, or \"true\") and $FP$ means \"_false positive_\" (a sample that was predicted positive, but the prediction was incorrect, or \"false\").  So, precision is the ratio of true positives to the total number of positive predictions.\n","\n","**_Recall_** is $\\frac{TP}{TP+FN}$, using the same notation, where the $FN$ means \"_false negative_\" (the sample was predicted as negative, but the prediction was incorrect, or \"false\").  So recall is the ratio of true positives to _actual positives_ in the sample.\n","\n","**_f1-score_** tries to show how well balanced the algorithm is.  The formula for f1-score is $\\frac{2\\cdot TP}{2\\cdot TP + FP + FN}$.  Like precision, recall, and accuracy, its range is $[0,1]$ with 1.0 being \"perfect\".\n","\n","**_Support_** just refers to the number of samples considered for the corresponding calculation."],"metadata":{"id":"F43qr3Nwfv9k"}},{"cell_type":"code","source":["# generate and print a classification report\n","# using sklearn's classification_report() function\n","print(sklearn.metrics.classification_report(\n","  y[test_set], \n","  predictions_categorical, \n","  labels=classes, \n","  target_names=class_names)\n",")"],"metadata":{"id":"dxLPlDlVfvVn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ROC Curve\n","Another common visualization and metric for discussing the performance of a classification model is the _Receiver Operating Characteristic_ (ROC) curve, and the area under that curve (often called the AUROC or just AUC). Check the references for the link to the documentation for this function.\n","\n","üèÄ       NOW IT'S YOUR TURN:"],"metadata":{"id":"GbdJ3feoeLUc"}},{"cell_type":"code","source":["# create a plot to visualize the accuracy of the model's predictions\n","# using RocCurveDisplay.from_predictions()\n","# the function needs the parameters: y[test_set], predictions_categorical\n","rc = \n","rc"],"metadata":{"id":"oevfrhBVfwCz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice that the AUC (area under the curve) is shown in the lower-right.  In this case, it is rounded to 1, but we know the model's performance was not perfect.  You would want to report this number along with other metrics to give a clear and fair assessment of the model's performance.\n","\n","We can also just determine the AUC value itself (without the graph) by using `sklearn.metrics.roc_auc_score`:"],"metadata":{"id":"nBaSP1nSfwI2"}},{"cell_type":"code","source":["# let's use some print statements to compare results\n","\n","print(\"Using only the binary label for inauthentic:\")\n","print(sklearn.metrics.roc_auc_score(y[test_set], predictions_categorical))\n","print(\"Using the predicted probability of being inauthentic:\")\n","print(sklearn.metrics.roc_auc_score(y[test_set], predictions[:,1]))"],"metadata":{"id":"h2f0e_b6fwNl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From this, we can see that there is some difference between comparing the quantized (categorical) labels versus the probabilities.  The probabilities allow a more representative calculation since the uncertainty in the predictions can be taken into account.  We also see that is is reasonable for the number to be rounded to 1.0 in the figure. (The `plot_roc_curve()` utilized the probabilites in the calculation)."],"metadata":{"id":"2MdvIRvVf5cF"}},{"cell_type":"markdown","source":["#References and Other Resources\n","\n","* \"Banknote Authentication\" dataset from the [UCI Machine Learning repository](https://archive.ics.uci.edu) at <https://archive.ics.uci.edu/ml/datasets/banknote+authentication>.\n","\n","* NumPy docs: https://numpy.org/\n","\n","* Pandas docs: https://pandas.pydata.org/\n","\n","* SciKit Learn docs: https://scikit-learn.org/stable/\n","\n","* SciKit Learn Classifier Comparison: <https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html> \n","\n","* sklearn LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression\n","\n","* sklearn confusion_matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay.from_predictions\n","\n","* sklearn roc_curve: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html#sklearn.metrics.RocCurveDisplay.from_predictions\n"],"metadata":{"id":"bpmk6FEwf5sG"}}]}